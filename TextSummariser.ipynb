{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxPPEfUY2OCLwJbOb9O1JO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shanmukh459/Text-summarization/blob/main/TextSummariser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPJmxsFfjXfj",
        "outputId": "9d9e2a3f-e2d8-4f8f-8584-738ad3b65887"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.7.22)\n",
            "Installing collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0UxgJFhPEBj",
        "outputId": "094bae73-f2b8-4744-c026-042516144fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import youtube_transcript_api\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "link = \"https://www.youtube.com/watch?v=Y8Tko2YC5hA\"\n",
        "unique_id = link.split(\"=\")[-1]\n",
        "sub = YouTubeTranscriptApi.get_transcript(unique_id)\n",
        "subtitle = \" \".join([x['text'] for x in sub])"
      ],
      "metadata": {
        "id": "h7CfL05wPlZ8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summarization with TF-IDF vectorization"
      ],
      "metadata": {
        "id": "5GoMBIy7QLL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "subtitle = subtitle.replace(\"\\n\", \"\")\n",
        "sentences = nltk.tokenize.sent_tokenize(subtitle)"
      ],
      "metadata": {
        "id": "BLW2eo7jQUAo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "organized_sent = {k:v for v,k in enumerate(sentences)}"
      ],
      "metadata": {
        "id": "CV-a6rqgQqvM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(min_df=2,\n",
        "                        strip_accents='unicode',\n",
        "                        max_features=None,\n",
        "                        lowercase=True,\n",
        "                        token_pattern=r'w{1,}',\n",
        "                        ngram_range=(1, 3),\n",
        "                        use_idf=1,\n",
        "                        smooth_idf=1,\n",
        "                        sublinear_tf=1,\n",
        "                        stop_words='english')"
      ],
      "metadata": {
        "id": "qMofmq5iQ05s"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_vectors = tfidf.fit_transform(sentences)\n",
        "sent_scores = np.array(sentence_vectors.sum(axis=1)).ravel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIrFUI81kC_u",
        "outputId": "bff037ab-cae4-4114-fd2b-33e2e9e9085e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py:558: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['w'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = 3\n",
        "top_n_sentences = [sentences[index] for index in np.argsort(sent_scores, axis=0)[::-1][:N]]"
      ],
      "metadata": {
        "id": "4px2W1hCkXyQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordering the sentences based on the order they appeared in the subtitles"
      ],
      "metadata": {
        "id": "-ADVxU4Lk901"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapped_sentences = [(sentence, organized_sent[sentence]) for sentence in top_n_sentences]\n",
        "\n",
        "mapped_sentences = sorted(mapped_sentences, key = lambda x: x[1])\n",
        "ordered_sentences = [element[0] for element in mapped_sentences]\n",
        "\n",
        "summary = \" \".join(ordered_sentences)"
      ],
      "metadata": {
        "id": "o7JpuofTk3RG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tluiDgEBlm4Z",
        "outputId": "d0afac07-a20b-413c-e80a-3adf196dbfe6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You ca also use Pytho to build  web, mobile ad desktop applicatios as well as software  testig or eve hackig. Let's say we wat to extract the first three  letters of the text Hello World. It's cross platform which meas  you ca build ad ru Pytho applicatios o Widows, Mac,  ad Liux.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xHkzE9nqlpmq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}